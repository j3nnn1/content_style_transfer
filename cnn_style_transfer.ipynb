{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-26 23:50:53--  https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\n",
      "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 223725 (218K) [image/jpeg]\n",
      "Saving to: ‘La_noche_estrellada1.jpg.7’\n",
      "\n",
      "La_noche_estrellada 100%[===================>] 218.48K   371KB/s    in 0.6s    \n",
      "\n",
      "2022-03-26 23:50:54 (371 KB/s) - ‘La_noche_estrellada1.jpg.7’ saved [223725/223725]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imagen para estilo\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-26 23:50:55--  https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\n",
      "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 153015 (149K) [image/jpeg]\n",
      "Saving to: ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.6’\n",
      "\n",
      "775px-Neckarfront_T 100%[===================>] 149.43K   322KB/s    in 0.5s    \n",
      "\n",
      "2022-03-26 23:50:56 (322 KB/s) - ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.6’ saved [153015/153015]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imagen para contenido\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./content/output’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# Creamos el directorio para los archivos de salida\n",
    "!mkdir ./content/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
    "#originales\n",
    "#base_image_path = Path(\"./775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
    "style_reference_image_path = Path(\"./La_noche_estrellada1.jpg\")\n",
    "\n",
    "\n",
    "base_image_path = Path(\"./playa.jpg\")\n",
    "# style_reference_image_path = Path(\"./wave_estilo.jpg\")\n",
    "\n",
    "# base_image_path = Path(\"./base_wichy2.jpg\")\n",
    "# style_reference_image_path = Path(\"./monetEstilo2.jpg\")\n",
    "result_prefix = Path(\"./content/output\")\n",
    "\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originales\n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 10\n",
    "# content_weight = 1\n",
    "\n",
    "total_variation_weight = 0.1\n",
    "style_weight = 10\n",
    "content_weight = 1\n",
    "\n",
    "\n",
    "# Respuesta:\n",
    "# La funcion loss que esta minimizando el paper se compone de dos elementos:\n",
    "#\n",
    "# el elemento que representa el contenido de la imagen  (content_weight) y el elemento que representa el estilo de la imagen (style_weight)\n",
    "# Entonces dependiendo de la proporcion de cada elemento la imagen resultante sera mejor o peor\n",
    "# si se le da mas peso al contenido, la imagen tendra pocos rasgos del estilo de la segunda imagen\n",
    "# en cambio si se da mas peso al estilo, se podria perder la estructura inicial de la primera imagen siendo irreconocible.\n",
    "# total_variation_weight tiene la relacion entre content_weight/style_weight\n",
    "# alfa (content_weight)/ beta (style_weight)\n",
    "# representaria los valores de la siguiente ecuacion presentada en el paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% md\n",
    "#![ecuacionLoss.png](attachment:ecuacionLoss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack to error: Could not import PIL.Image. The use of `load_img` requires PIL.\n",
    "# uninstall pillow from conda and install by pip\n",
    "# NO LO USE\n",
    "#import sys\n",
    "#from PIL import Image\n",
    "#sys.modules['Image'] = Image \n",
    "\n",
    "#from PIL import Image\n",
    "#print(Image.__file__)\n",
    "\n",
    "#import Image\n",
    "#print(Image.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Definimos el tamaño de las imágenes a utilizar\n",
    "width, height = load_img(base_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
    "#Ayuda: https://keras.io/applications/ => https://keras.io/api/applications/vgg/#vgg19-function\n",
    "\n",
    "#Respuesta:\n",
    "# cada keras application espera un tipo especifico de formato y tamano del vector\n",
    "# por ejemplo vgg19 requiere que las imagenes esten en BGR\n",
    "# y no en RGB. y centrara en zero cada canal de color con respecto al dataset ImageNet.\n",
    "# img # (400, 517, 3)\n",
    "# img after preprocess # (1, 400, 517, 3)\n",
    "# de acuerdo a la documentacion de VGG19 es necesario expandir el array en 1 dimension para poder procesar en batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
    "\n",
    "# Respuesta:\n",
    "# como las imagenes para ser usadas en VGG19 necesitan un formato especifico BGR y la normalizacion centrada en 0.\n",
    "# la salida necesita tener el  proceso inverso para obtener la imagen en el formato RGB, y los valores correctos en los canales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deprocess_image(x):\n",
    "    x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style image\n",
    "# get tensor representations of our images\n",
    "# K.variable convierte un numpy array en un tensor, para \n",
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aclaración:\n",
    "\n",
    "#La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# combine the 3 images into a single Keras tensor\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 23:50:57.967974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-26 23:50:57.968604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-26 23:50:57.968713: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-26 23:50:57.968804: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-26 23:50:57.968894: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-26 23:50:57.968984: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-26 23:50:57.969072: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-26 23:50:57.969685: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-26 23:50:57.969805: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-03-26 23:50:57.969824: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build the VGG19 network with our 3 images as input\n",
    "# the model will be loaded with pre-trained ImageNet weights\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'block1_conv1/Relu:0' shape=(3, 400, 520, 64) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_features2 = outputs_dict['block1_conv1'] # 400,517,3 or 64\n",
    "# layer_features2[1, :, :, :] \n",
    "# layer_features2[2, :, :, :] \n",
    "layer_features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=(400, 520, 64) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict['block1_conv1'][2] # 400,517,3 or 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_1:0' shape=(200, 260, 128) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict['block2_conv1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_2:0' shape=(100, 130, 256) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict['block3_conv1'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_3:0' shape=(50, 65, 512) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict['block4_conv1'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_4:0' shape=(25, 32, 512) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict['block5_conv1'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) En la siguientes celdas:\n",
    "\n",
    "#- ¿Qué es la matriz de Gram?¿Para qué se usa?\n",
    "\n",
    "#Es una matriz que contiene el producto punto entre dos vectores para extraer el estilo (textura) de una imagen, esto indica cuan similar son estos dos vectores, para luego\n",
    "#calcular la funcion de optimizacion \"style loss\". Este producto punto devuelve informacion sobre la textura de la imagen y\n",
    "#Zero informacion sobre su estructura espacial (Contenido).\n",
    "\n",
    "#Gram matrix es el resultado del producto punto de un vector que representa \"features maps\" de una cnn.\n",
    "#un feature map puede ser textures, brush strokes, lines, curves, dots, color distribution.\n",
    "#Esto usa vectores aplanados de tamano C a partir de la capa de una cnn de profundidad C. (CxC)\n",
    "# Para cada layer se genera una gram matrix entonces de esto se calcula el mse loss, y sumariza por cada capa.\n",
    "\n",
    "# En sintesis Gram matrix se usa para capturar el estilo a partir de caracteristicas \"features map / features metrics\" de una CNN.\n",
    "\n",
    "#- ¿Por qué se permutan las dimensiones de x?\n",
    "# Para tener una estructura donde se pueda realizar el producto punto, requerido por la matrix transpuesta.\n",
    "# x consiste en un tensor donde la posicion 2 corresponde a un batch de 64\n",
    "# la posicion 0 e 1 corresponde al numero de filas y columnas que representan a la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Losses:\n",
    "\n",
    "#Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
    "\n",
    "#Rta: \n",
    "# style_loss mide que tan cercano es el estilo de la imagen de referencia de estilo con la imagen de entrada base.\n",
    "# utilizando este valor permite obtener la textura o estilo de una imagen y\n",
    "# minimizando esta diferencia a traves de las distintas capas de la red.\n",
    "#\n",
    "# content_loss \n",
    "# contiene la distancia o medicion que tan cercana es la imagen de entrada base con la imagen combinada (la imagen nueva con parte del estilo de referencia)\n",
    "# donde si bien mientras mas cercana al contenido mas puede estar alejada del estilo de referencia\n",
    "# por lo que es necesario la combinacion de ambas metricas tanto el style loss como el content loss \n",
    "# para obtener una imagen coherente y no perder el 100%  de la  estructura de la imagen base.\n",
    "# \n",
    "# total_variation_loss\n",
    "# total_variation_loss(combination_image)\n",
    "# es como un suavisado de la imagen, toma la matriz o tensor que representa la imagen nueva generada \n",
    "# y reduce que se produzcan fuertes cambios en los valores. \n",
    "# y evitando la eliminacion ruido blanco de la imagen nueva generada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    a = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "    b = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Armamos la loss total\n",
    "loss = K.variable(0.0)\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss = loss + content_weight * content_loss(base_image_features,\n",
    "                                            combination_features)\n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :] \n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
    "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #initialize the variable\n",
    "# #init_op = tf.initialize_all_variables()\n",
    "# init = tf.compat.v1.global_variables_initializer()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init_op) #execute init_op\n",
    "#     #print the random values that we sample\n",
    "#     print (sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import tensorflow as tf\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "#from tensorflow.python.framework.ops import disable_eager_execution\n",
    "#disable_eager_execution()\n",
    "\n",
    "\n",
    "grads = K.gradients(loss, combination_image)\n",
    "#grads = tf.GradientTape(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
    "\n",
    "#Respuesta:\n",
    "\n",
    "# fmin_l_bfgs_b \n",
    "# es un algoritmo  de la familia de metodos Quasi-Newton, donde tiene como objetivo optimizar una funcion y buscar \n",
    "# los extremos locales de una funcion. Trabaja bien con datasets largos ya que necesita menos memoria que el algoritmo estandar BFGS.\n",
    "# En este caso se utiliza para minimizar *la funcion global loss* que se compone  de los siguientes elementos: style loss, content loss, y total loss.\n",
    "\n",
    "# ¿En qué se diferencia con la implementación del paper? \n",
    "# En el paper usan el descenso del gradiente para minimizar las loss. \n",
    "# Y no se visualiza el uso de alguna funcion o Ecuacion de suavizado sobre la imagen nueva generada como \n",
    "# \"total_variation_loss\" es usada en esta notebook para ese suavizado.\n",
    "# ¿Se puede utilizar alguna alternativa? Si, standard error back-propagation. o descenso del gradiente\n",
    "\n",
    "# celda 1 = eval_loss_and_grads funcion que \n",
    "# evalua la loss y el valor del gradiente para la imagen X, x seria la imagen nueva generada.\n",
    "# devuelve el valor de la loss y el gradiente en el tipo de dato float64\n",
    "#\n",
    "# celda 2 = evaluator\n",
    "# es una clase que representa al Evaluador y tiene dos atributos loss y los valores del gradiente\n",
    "# inicializa los valores en Null, y usa la funcion de la celda anterior (eval_loss_and_grads) \n",
    "# para ir variando los valores de la loss\n",
    "# y el valor del gradiente\n",
    "\n",
    "# celda 3 = implentacion del uso de evaluator\n",
    "# preprocesa la imagen  (normalizacion y pasar de BGR a RGB)\n",
    "# de acuerdo a la cantidad de iteraciones definidas para cada iteracion:\n",
    "# utiliza el algoritmo \"\" para minimizar la loss y lo guarda en una variable \"\"\n",
    "# luego copia el vector (x.copy()), despreprocesa la imagen (BGR -> RGB) y guarda la imagen para esa iteracion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# this Evaluator class makes it possible\n",
    "# to compute loss and gradients in one pass\n",
    "# while retrieving them via two separate functions,\n",
    "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
    "# requires separate functions for loss and gradients,\n",
    "# but computing them separately would be inefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 23:51:01.060641: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19968000 exceeds 10% of free system memory.\n",
      "2022-03-26 23:51:01.069614: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 39936000 exceeds 10% of free system memory.\n",
      "2022-03-26 23:51:01.087025: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 79872000 exceeds 10% of free system memory.\n",
      "2022-03-26 23:51:01.123845: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 159744000 exceeds 10% of free system memory.\n",
      "2022-03-26 23:51:01.210101: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19968000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss\n",
    "x = preprocess_image(base_image_path)\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
    "    save_img(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
    "\n",
    "#Respuesta:\n",
    "# combinaciones de pesos de las losses\n",
    "# primera ejecucion:\n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 10\n",
    "# content_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinaciones de pesos de las losses\n",
    "# segunda ejecucion:\n",
    "# total_variation_weight = 0.2\n",
    "# style_weight = 100\n",
    "# content_weight = 1\n",
    "# alfa (content_weight)/ beta (style_weight)\n",
    "# cambio un poco la intensidad de los colores, con esta combinacion tiene colores mas oscuros y mate\n",
    "# tiene pocas diferencias con respecto a la anterior configuracion pero se nota un poco en los colores \n",
    "# tendiendo hacia la paleta de colores de la imagen de estilo de referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinaciones de pesos de las losses\n",
    "# tercera ejecucion:\n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 1\n",
    "# content_weight = 10\n",
    "\n",
    "#se visualiza que las lineas, formas y estructura del contenido se mantiene,  muy poco varia a diferencia de la anterior \n",
    "# ejecucion donde las luces, y formas circulares tomaban mas la estructura de la imagen de referencia del estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinaciones de pesos de las losses\n",
    "# cuarta ejecucion:\n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 1\n",
    "# content_weight = 10000\n",
    "# muy claro que muestra pocos cambios de estilo y la paleta de colores es identica a la fotografia original\n",
    "# conserva claramente la estructura del contenido y tambien los colores, algunas lineas tienen el estilo de\n",
    "# la fotografia de referencia del estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
    "\n",
    "#Respuesta:\n",
    "\n",
    "# quinta ejecucion\n",
    "# imagenes diferentes\n",
    "# pesos \n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 1\n",
    "# content_weight = 10000\n",
    "# no se vio ningun cambio ya que se hacia referencia a mantener la estructura del contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the wave style\n",
    "# playa mar del plata\n",
    "# sexta ejecucion\n",
    "# total_variation_weight = 0.2\n",
    "# style_weight = 100\n",
    "# content_weight = 1\n",
    "# se visualiza el cambio de estilo. y no se preserva tanto el contenido (habian personas y edificios que se distorsionaron con los cambios)\n",
    "# los cambios se visualizan en algunos casos de forma brusca,\n",
    "# la paleta de colores en las iteraciones mas altas se asemejan a la paleta de colores usada por el estilo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# octava ejecucion \n",
    "# wichy_base2.jpg y un monet2\n",
    "# monet 1 style\n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 10\n",
    "# content_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# septima ejecucion\n",
    "# base_wichy.jpg\n",
    "# monet 2 style\n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 10\n",
    "# content_weight = 1\n",
    "# se visualizan los cambios de estilo, e incluso se ve que se pierde un poco la estructura del contenido.\n",
    "# la paleta de colores del estilo empieza a estar presente en la imagen nueva a pesar que no posee \n",
    "# contenido relacionado con ese color\n",
    "# el suavizado de los cambios es sutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}