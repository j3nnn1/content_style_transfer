{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-09 23:27:40--  https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
      "SSL_INIT\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\n",
      "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 223725 (218K) [image/jpeg]\n",
      "Saving to: ‘La_noche_estrellada1.jpg.6’\n",
      "\n",
      "La_noche_estrellada 100%[===================>] 218.48K   336KB/s    in 0.7s    \n",
      "\n",
      "2022-03-09 23:27:42 (336 KB/s) - ‘La_noche_estrellada1.jpg.6’ saved [223725/223725]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imagen para estilo\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-09 23:27:42--  https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
      "SSL_INIT\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\n",
      "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 153015 (149K) [image/jpeg]\n",
      "Saving to: ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.5’\n",
      "\n",
      "775px-Neckarfront_T 100%[===================>] 149.43K   285KB/s    in 0.5s    \n",
      "\n",
      "2022-03-09 23:27:44 (285 KB/s) - ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.5’ saved [153015/153015]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imagen para contenido\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./content/output’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# Creamos el directorio para los archivos de salida\n",
    "!mkdir ./content/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
    "#originales\n",
    "#base_image_path = Path(\"./775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
    "#style_reference_image_path = Path(\"./La_noche_estrellada1.jpg\")\n",
    "\n",
    "\n",
    "base_image_path = Path(\"./playa.jpg\")\n",
    "style_reference_image_path = Path(\"./wave_estilo.jpg\")\n",
    "result_prefix = Path(\"./content/output\")\n",
    "\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originales\n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 10\n",
    "# content_weight = 1\n",
    "\n",
    "total_variation_weight = 0.2\n",
    "style_weight = 100\n",
    "content_weight = 1\n",
    "\n",
    "\n",
    "# Respuesta:\n",
    "# La funcion loss que esta minimizando el paper se compone de dos elementos:\n",
    "#\n",
    "# el elemento que representa el contenido de la imagen  (content_weight) y el elemento que representa el estilo de la imagen (style_weight)\n",
    "# Entonces dependiendo de la proporcion de cada elemento la imagen resultante sera mejor o peor\n",
    "# si se le da mas peso al contenido, la imagen tendra pocos rasgos del estilo de la segunda imagen\n",
    "# en cambio si se da mas peso al estilo, se podria perder la estructura inicial de la primera imagen siendo irreconocible.\n",
    "# total_variation_weight tiene la relacion entre content_weight/style_weight\n",
    "# alfa (content_weight)/ beta (style_weight)\n",
    "# representaria los valores de la siguiente ecuacion presentada en el paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: number expected\r\n"
     ]
    }
   ],
   "source": [
    "#%% md\n",
    "![ecuacionLoss.png](attachment:ecuacionLoss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack to error: Could not import PIL.Image. The use of `load_img` requires PIL.\n",
    "# uninstall pillow from conda and install by pip\n",
    "# NO LO USE\n",
    "#import sys\n",
    "#from PIL import Image\n",
    "#sys.modules['Image'] = Image \n",
    "\n",
    "#from PIL import Image\n",
    "#print(Image.__file__)\n",
    "\n",
    "#import Image\n",
    "#print(Image.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Definimos el tamaño de las imágenes a utilizar\n",
    "width, height = load_img(base_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
    "#Ayuda: https://keras.io/applications/ => https://keras.io/api/applications/vgg/#vgg19-function\n",
    "\n",
    "#Respuesta:\n",
    "# cada keras application espera un tipo especifico de formato y tamano del vector\n",
    "# por ejemplo vgg19 requiere que las imagenes esten en BGR\n",
    "# y no en RGB. y centrara en zero cada canal de color con respecto al dataset ImageNet.\n",
    "# img # (400, 517, 3)\n",
    "# img after preprocess # (1, 400, 517, 3)\n",
    "# de acuerdo a la documentacion de VGG19 es necesario expandir el array en 1 dimension para poder procesar en batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
    "\n",
    "# Respuesta:\n",
    "# como las imagenes para ser usadas en VGG19 necesitan un formato especifico BGR y la normalizacion centrada en 0.\n",
    "# la salida necesita tener el  proceso inverso para obtener la imagen en el formato RGB, y los valores correctos en los canales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deprocess_image(x):\n",
    "    x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style image\n",
    "# get tensor representations of our images\n",
    "# K.variable convierte un numpy array en un tensor, para \n",
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aclaración:\n",
    "\n",
    "#La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# combine the 3 images into a single Keras tensor\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build the VGG19 network with our 3 images as input\n",
    "# the model will be loaded with pre-trained ImageNet weights\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'block1_conv1_8/Relu:0' shape=(3, 400, 520, 64) dtype=float32>"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_features2 = outputs_dict['block1_conv1'] # 400,517,3 or 64\n",
    "# layer_features2[1, :, :, :] \n",
    "# layer_features2[2, :, :, :] \n",
    "layer_features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_274:0' shape=(400, 520, 64) dtype=float32>"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict['block1_conv1'][2] # 400,517,3 or 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_275:0' shape=(200, 260, 128) dtype=float32>"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict['block2_conv1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_276:0' shape=(100, 130, 256) dtype=float32>"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict['block3_conv1'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_277:0' shape=(50, 65, 512) dtype=float32>"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict['block4_conv1'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_278:0' shape=(25, 32, 512) dtype=float32>"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict['block5_conv1'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) En la siguientes celdas:\n",
    "\n",
    "#- ¿Qué es la matriz de Gram?¿Para qué se usa?\n",
    "\n",
    "#Es una matriz que contiene el producto punto entre dos vectores para extraer el estilo (textura) de una imagen, esto indica cuan similar son estos dos vectores, para luego\n",
    "#calcular la funcion de optimizacion \"style loss\". Este producto punto devuelve informacion sobre la textura de la imagen y\n",
    "#Zero informacion sobre su estructura espacial (Contenido).\n",
    "\n",
    "#Gram matrix es el resultado del producto punto de un vector que representa \"features maps\" de una cnn.\n",
    "#un feature map puede ser textures, brush strokes, lines, curves, dots, color distribution.\n",
    "#Esto usa vectores aplanados de tamano C a partir de la capa de una cnn de profundidad C. (CxC)\n",
    "# Para cada layer se genera una gram matrix entonces de esto se calcula el mse loss, y sumariza por cada capa.\n",
    "\n",
    "# En sintesis Gram matrix se usa para capturar el estilo a partir de caracteristicas \"features map / features metrics\" de una CNN.\n",
    "\n",
    "#- ¿Por qué se permutan las dimensiones de x?\n",
    "# Para tener una estructura donde se pueda realizar el producto punto, requerido por la matrix transpuesta.\n",
    "# x consiste en un tensor donde la posicion 2 corresponde a un batch de 64\n",
    "# la posicion 0 e 1 corresponde al numero de filas y columnas que representan a la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Losses:\n",
    "\n",
    "#Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
    "\n",
    "#Rta: \n",
    "# style_loss mide que tan cercano es el estilo de la imagen de referencia de estilo con la imagen de entrada base.\n",
    "# utilizando este valor permite obtener la textura o estilo de una imagen y\n",
    "# minimizando esta diferencia a traves de las distintas capas de la red.\n",
    "#\n",
    "# content_loss \n",
    "# contiene la distancia o medicion que tan cercana es la imagen de entrada base con la imagen combinada (la imagen nueva con parte del estilo de referencia)\n",
    "# donde si bien mientras mas cercana al contenido mas puede estar alejada del estilo de referencia\n",
    "# por lo que es necesario la combinacion de ambas metricas tanto el style loss como el content loss \n",
    "# para obtener una imagen coherente y no perder el 100%  de la  estructura de la imagen base.\n",
    "# \n",
    "# total_variation_loss\n",
    "# total_variation_loss(combination_image)\n",
    "# es como un suavisado de la imagen, toma la matriz o tensor que representa la imagen nueva generada \n",
    "# y reduce que se produzcan fuertes cambios en los valores. \n",
    "# y evitando la eliminacion ruido blanco de la imagen nueva generada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    a = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "    b = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Armamos la loss total\n",
    "loss = K.variable(0.0)\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss = loss + content_weight * content_loss(base_image_features,\n",
    "                                            combination_features)\n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :] \n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
    "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #initialize the variable\n",
    "# #init_op = tf.initialize_all_variables()\n",
    "# init = tf.compat.v1.global_variables_initializer()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init_op) #execute init_op\n",
    "#     #print the random values that we sample\n",
    "#     print (sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import tensorflow as tf\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "#from tensorflow.python.framework.ops import disable_eager_execution\n",
    "#disable_eager_execution()\n",
    "\n",
    "\n",
    "grads = K.gradients(loss, combination_image)\n",
    "#grads = tf.GradientTape(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
    "\n",
    "#Respuesta:\n",
    "\n",
    "# fmin_l_bfgs_b \n",
    "# es un algoritmo  de la familia de metodos Quasi-Newton, donde tiene como objetivo optimizar una funcion y buscar \n",
    "# los extremos locales de una funcion. Trabaja bien con datasets largos ya que necesita menos memoria que el algoritmo estandar BFGS.\n",
    "# En este caso se utiliza para minimizar *la funcion global loss* que se compone  de los siguientes elementos: style loss, content loss, y total loss.\n",
    "\n",
    "# ¿En qué se diferencia con la implementación del paper? \n",
    "# En el paper usan el descenso del gradiente para minimizar las loss. \n",
    "# Y no se visualiza el uso de alguna funcion o Ecuacion de suavizado sobre la imagen nueva generada como \n",
    "# \"total_variation_loss\" es usada en esta notebook para ese suavizado.\n",
    "# ¿Se puede utilizar alguna alternativa? Si, standard error back-propagation. o descenso del gradiente\n",
    "\n",
    "# celda 1 = eval_loss_and_grads funcion que \n",
    "# evalua la loss y el valor del gradiente para la imagen X, x seria la imagen nueva generada.\n",
    "# devuelve el valor de la loss y el gradiente en el tipo de dato float64\n",
    "#\n",
    "# celda 2 = evaluator\n",
    "# es una clase que representa al Evaluador y tiene dos atributos loss y los valores del gradiente\n",
    "# inicializa los valores en Null, y usa la funcion de la celda anterior (eval_loss_and_grads) \n",
    "# para ir variando los valores de la loss\n",
    "# y el valor del gradiente\n",
    "\n",
    "# celda 3 = implentacion del uso de evaluator\n",
    "# preprocesa la imagen  (normalizacion y pasar de BGR a RGB)\n",
    "# de acuerdo a la cantidad de iteraciones definidas para cada iteracion:\n",
    "# utiliza el algoritmo \"\" para minimizar la loss y lo guarda en una variable \"\"\n",
    "# luego copia el vector (x.copy()), despreprocesa la imagen (BGR -> RGB) y guarda la imagen para esa iteracion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# this Evaluator class makes it possible\n",
    "# to compute loss and gradients in one pass\n",
    "# while retrieving them via two separate functions,\n",
    "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
    "# requires separate functions for loss and gradients,\n",
    "# but computing them separately would be inefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "Current loss value: 108933950000.0\n",
      "Image saved as content/output/output_at_iteration_0.png\n",
      "Iteration 0 completed in 357s\n",
      "Start of iteration 1\n",
      "Current loss value: 57507586000.0\n",
      "Image saved as content/output/output_at_iteration_1.png\n",
      "Iteration 1 completed in 381s\n",
      "Start of iteration 2\n",
      "Current loss value: 41749480000.0\n",
      "Image saved as content/output/output_at_iteration_2.png\n",
      "Iteration 2 completed in 364s\n",
      "Start of iteration 3\n",
      "Current loss value: 33484022000.0\n",
      "Image saved as content/output/output_at_iteration_3.png\n",
      "Iteration 3 completed in 365s\n",
      "Start of iteration 4\n",
      "Current loss value: 28370323000.0\n",
      "Image saved as content/output/output_at_iteration_4.png\n",
      "Iteration 4 completed in 366s\n",
      "Start of iteration 5\n",
      "Current loss value: 24218776000.0\n",
      "Image saved as content/output/output_at_iteration_5.png\n",
      "Iteration 5 completed in 366s\n",
      "Start of iteration 6\n",
      "Current loss value: 21334706000.0\n",
      "Image saved as content/output/output_at_iteration_6.png\n",
      "Iteration 6 completed in 371s\n",
      "Start of iteration 7\n",
      "Current loss value: 19374162000.0\n",
      "Image saved as content/output/output_at_iteration_7.png\n",
      "Iteration 7 completed in 366s\n",
      "Start of iteration 8\n",
      "Current loss value: 17584456000.0\n",
      "Image saved as content/output/output_at_iteration_8.png\n",
      "Iteration 8 completed in 366s\n",
      "Start of iteration 9\n",
      "Current loss value: 16356369000.0\n",
      "Image saved as content/output/output_at_iteration_9.png\n",
      "Iteration 9 completed in 366s\n",
      "Start of iteration 10\n",
      "Current loss value: 15380189000.0\n",
      "Image saved as content/output/output_at_iteration_10.png\n",
      "Iteration 10 completed in 367s\n",
      "Start of iteration 11\n",
      "Current loss value: 14394690000.0\n",
      "Image saved as content/output/output_at_iteration_11.png\n",
      "Iteration 11 completed in 365s\n",
      "Start of iteration 12\n",
      "Current loss value: 13547900000.0\n",
      "Image saved as content/output/output_at_iteration_12.png\n",
      "Iteration 12 completed in 370s\n",
      "Start of iteration 13\n",
      "Current loss value: 12698457000.0\n",
      "Image saved as content/output/output_at_iteration_13.png\n",
      "Iteration 13 completed in 366s\n",
      "Start of iteration 14\n",
      "Current loss value: 11957071000.0\n",
      "Image saved as content/output/output_at_iteration_14.png\n",
      "Iteration 14 completed in 366s\n",
      "Start of iteration 15\n",
      "Current loss value: 11364599000.0\n",
      "Image saved as content/output/output_at_iteration_15.png\n",
      "Iteration 15 completed in 365s\n",
      "Start of iteration 16\n",
      "Current loss value: 10816853000.0\n",
      "Image saved as content/output/output_at_iteration_16.png\n",
      "Iteration 16 completed in 364s\n",
      "Start of iteration 17\n",
      "Current loss value: 10303415000.0\n",
      "Image saved as content/output/output_at_iteration_17.png\n",
      "Iteration 17 completed in 364s\n",
      "Start of iteration 18\n",
      "Current loss value: 9816188000.0\n",
      "Image saved as content/output/output_at_iteration_18.png\n",
      "Iteration 18 completed in 365s\n",
      "Start of iteration 19\n",
      "Current loss value: 9425821000.0\n",
      "Image saved as content/output/output_at_iteration_19.png\n",
      "Iteration 19 completed in 365s\n",
      "Start of iteration 20\n",
      "Current loss value: 9029928000.0\n",
      "Image saved as content/output/output_at_iteration_20.png\n",
      "Iteration 20 completed in 369s\n",
      "Start of iteration 21\n",
      "Current loss value: 8650375000.0\n",
      "Image saved as content/output/output_at_iteration_21.png\n",
      "Iteration 21 completed in 365s\n",
      "Start of iteration 22\n",
      "Current loss value: 8289318400.0\n",
      "Image saved as content/output/output_at_iteration_22.png\n",
      "Iteration 22 completed in 366s\n",
      "Start of iteration 23\n",
      "Current loss value: 8003242500.0\n",
      "Image saved as content/output/output_at_iteration_23.png\n",
      "Iteration 23 completed in 366s\n",
      "Start of iteration 24\n",
      "Current loss value: 7739151000.0\n",
      "Image saved as content/output/output_at_iteration_24.png\n",
      "Iteration 24 completed in 365s\n",
      "Start of iteration 25\n",
      "Current loss value: 7427976700.0\n",
      "Image saved as content/output/output_at_iteration_25.png\n",
      "Iteration 25 completed in 365s\n",
      "Start of iteration 26\n",
      "Current loss value: 7158907400.0\n",
      "Image saved as content/output/output_at_iteration_26.png\n",
      "Iteration 26 completed in 368s\n",
      "Start of iteration 27\n",
      "Current loss value: 6907083300.0\n",
      "Image saved as content/output/output_at_iteration_27.png\n",
      "Iteration 27 completed in 365s\n",
      "Start of iteration 28\n",
      "Current loss value: 6673228000.0\n",
      "Image saved as content/output/output_at_iteration_28.png\n",
      "Iteration 28 completed in 364s\n",
      "Start of iteration 29\n",
      "Current loss value: 6444941300.0\n",
      "Image saved as content/output/output_at_iteration_29.png\n",
      "Iteration 29 completed in 365s\n",
      "Start of iteration 30\n",
      "Current loss value: 6225419300.0\n",
      "Image saved as content/output/output_at_iteration_30.png\n",
      "Iteration 30 completed in 370s\n",
      "Start of iteration 31\n",
      "Current loss value: 6032770600.0\n",
      "Image saved as content/output/output_at_iteration_31.png\n",
      "Iteration 31 completed in 371s\n",
      "Start of iteration 32\n",
      "Current loss value: 5817637400.0\n",
      "Image saved as content/output/output_at_iteration_32.png\n",
      "Iteration 32 completed in 369s\n",
      "Start of iteration 33\n",
      "Current loss value: 5623892500.0\n",
      "Image saved as content/output/output_at_iteration_33.png\n",
      "Iteration 33 completed in 366s\n",
      "Start of iteration 34\n",
      "Current loss value: 5431796000.0\n",
      "Image saved as content/output/output_at_iteration_34.png\n",
      "Iteration 34 completed in 366s\n",
      "Start of iteration 35\n",
      "Current loss value: 5255895000.0\n",
      "Image saved as content/output/output_at_iteration_35.png\n",
      "Iteration 35 completed in 383s\n",
      "Start of iteration 36\n",
      "Current loss value: 5104650000.0\n",
      "Image saved as content/output/output_at_iteration_36.png\n",
      "Iteration 36 completed in 366s\n",
      "Start of iteration 37\n",
      "Current loss value: 4941956600.0\n",
      "Image saved as content/output/output_at_iteration_37.png\n",
      "Iteration 37 completed in 366s\n",
      "Start of iteration 38\n",
      "Current loss value: 4769749500.0\n",
      "Image saved as content/output/output_at_iteration_38.png\n",
      "Iteration 38 completed in 366s\n",
      "Start of iteration 39\n",
      "Current loss value: 4607596000.0\n",
      "Image saved as content/output/output_at_iteration_39.png\n",
      "Iteration 39 completed in 371s\n",
      "Start of iteration 40\n",
      "Current loss value: 4483746000.0\n",
      "Image saved as content/output/output_at_iteration_40.png\n",
      "Iteration 40 completed in 367s\n",
      "Start of iteration 41\n",
      "Current loss value: 4357496300.0\n",
      "Image saved as content/output/output_at_iteration_41.png\n",
      "Iteration 41 completed in 366s\n",
      "Start of iteration 42\n",
      "Current loss value: 4236419300.0\n",
      "Image saved as content/output/output_at_iteration_42.png\n",
      "Iteration 42 completed in 370s\n",
      "Start of iteration 43\n",
      "Current loss value: 4122303500.0\n",
      "Image saved as content/output/output_at_iteration_43.png\n",
      "Iteration 43 completed in 367s\n",
      "Start of iteration 44\n",
      "Current loss value: 4018962700.0\n",
      "Image saved as content/output/output_at_iteration_44.png\n",
      "Iteration 44 completed in 366s\n",
      "Start of iteration 45\n",
      "Current loss value: 3925139200.0\n",
      "Image saved as content/output/output_at_iteration_45.png\n",
      "Iteration 45 completed in 367s\n",
      "Start of iteration 46\n",
      "Current loss value: 3815024000.0\n",
      "Image saved as content/output/output_at_iteration_46.png\n",
      "Iteration 46 completed in 367s\n",
      "Start of iteration 47\n",
      "Current loss value: 3709810400.0\n",
      "Image saved as content/output/output_at_iteration_47.png\n",
      "Iteration 47 completed in 367s\n",
      "Start of iteration 48\n",
      "Current loss value: 3620917200.0\n",
      "Image saved as content/output/output_at_iteration_48.png\n",
      "Iteration 48 completed in 367s\n",
      "Start of iteration 49\n",
      "Current loss value: 3539624000.0\n",
      "Image saved as content/output/output_at_iteration_49.png\n",
      "Iteration 49 completed in 367s\n",
      "Start of iteration 50\n",
      "Current loss value: 3476242400.0\n",
      "Image saved as content/output/output_at_iteration_50.png\n",
      "Iteration 50 completed in 370s\n",
      "Start of iteration 51\n",
      "Current loss value: 3408274400.0\n",
      "Image saved as content/output/output_at_iteration_51.png\n",
      "Iteration 51 completed in 366s\n",
      "Start of iteration 52\n",
      "Current loss value: 3348876000.0\n",
      "Image saved as content/output/output_at_iteration_52.png\n",
      "Iteration 52 completed in 367s\n",
      "Start of iteration 53\n",
      "Current loss value: 3288512500.0\n",
      "Image saved as content/output/output_at_iteration_53.png\n",
      "Iteration 53 completed in 367s\n",
      "Start of iteration 54\n",
      "Current loss value: 3232173000.0\n",
      "Image saved as content/output/output_at_iteration_54.png\n",
      "Iteration 54 completed in 371s\n",
      "Start of iteration 55\n",
      "Current loss value: 3152062700.0\n",
      "Image saved as content/output/output_at_iteration_55.png\n",
      "Iteration 55 completed in 372s\n",
      "Start of iteration 56\n",
      "Current loss value: 3091303700.0\n",
      "Image saved as content/output/output_at_iteration_56.png\n",
      "Iteration 56 completed in 373s\n",
      "Start of iteration 57\n",
      "Current loss value: 3038427000.0\n",
      "Image saved as content/output/output_at_iteration_57.png\n",
      "Iteration 57 completed in 366s\n",
      "Start of iteration 58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 2990881800.0\n",
      "Image saved as content/output/output_at_iteration_58.png\n",
      "Iteration 58 completed in 366s\n",
      "Start of iteration 59\n",
      "Current loss value: 2948320500.0\n",
      "Image saved as content/output/output_at_iteration_59.png\n",
      "Iteration 59 completed in 371s\n",
      "Start of iteration 60\n",
      "Current loss value: 2887857700.0\n",
      "Image saved as content/output/output_at_iteration_60.png\n",
      "Iteration 60 completed in 372s\n",
      "Start of iteration 61\n",
      "Current loss value: 2812857300.0\n",
      "Image saved as content/output/output_at_iteration_61.png\n",
      "Iteration 61 completed in 371s\n",
      "Start of iteration 62\n",
      "Current loss value: 2757162000.0\n",
      "Image saved as content/output/output_at_iteration_62.png\n",
      "Iteration 62 completed in 367s\n",
      "Start of iteration 63\n",
      "Current loss value: 2699862800.0\n",
      "Image saved as content/output/output_at_iteration_63.png\n",
      "Iteration 63 completed in 369s\n",
      "Start of iteration 64\n",
      "Current loss value: 2657243400.0\n",
      "Image saved as content/output/output_at_iteration_64.png\n",
      "Iteration 64 completed in 370s\n",
      "Start of iteration 65\n",
      "Current loss value: 2616339700.0\n",
      "Image saved as content/output/output_at_iteration_65.png\n",
      "Iteration 65 completed in 369s\n",
      "Start of iteration 66\n",
      "Current loss value: 2577565400.0\n",
      "Image saved as content/output/output_at_iteration_66.png\n",
      "Iteration 66 completed in 370s\n",
      "Start of iteration 67\n",
      "Current loss value: 2537259800.0\n",
      "Image saved as content/output/output_at_iteration_67.png\n",
      "Iteration 67 completed in 369s\n",
      "Start of iteration 68\n",
      "Current loss value: 2505775900.0\n",
      "Image saved as content/output/output_at_iteration_68.png\n",
      "Iteration 68 completed in 368s\n",
      "Start of iteration 69\n",
      "Current loss value: 2475800000.0\n",
      "Image saved as content/output/output_at_iteration_69.png\n",
      "Iteration 69 completed in 369s\n",
      "Start of iteration 70\n",
      "Current loss value: 2447773200.0\n",
      "Image saved as content/output/output_at_iteration_70.png\n",
      "Iteration 70 completed in 370s\n",
      "Start of iteration 71\n",
      "Current loss value: 2421916400.0\n",
      "Image saved as content/output/output_at_iteration_71.png\n",
      "Iteration 71 completed in 370s\n",
      "Start of iteration 72\n",
      "Current loss value: 2386720000.0\n",
      "Image saved as content/output/output_at_iteration_72.png\n",
      "Iteration 72 completed in 370s\n",
      "Start of iteration 73\n",
      "Current loss value: 2358131700.0\n",
      "Image saved as content/output/output_at_iteration_73.png\n",
      "Iteration 73 completed in 369s\n",
      "Start of iteration 74\n",
      "Current loss value: 2333008400.0\n",
      "Image saved as content/output/output_at_iteration_74.png\n",
      "Iteration 74 completed in 370s\n",
      "Start of iteration 75\n",
      "Current loss value: 2307227100.0\n",
      "Image saved as content/output/output_at_iteration_75.png\n",
      "Iteration 75 completed in 369s\n",
      "Start of iteration 76\n",
      "Current loss value: 2287510000.0\n",
      "Image saved as content/output/output_at_iteration_76.png\n",
      "Iteration 76 completed in 369s\n",
      "Start of iteration 77\n",
      "Current loss value: 2267396000.0\n",
      "Image saved as content/output/output_at_iteration_77.png\n",
      "Iteration 77 completed in 370s\n",
      "Start of iteration 78\n",
      "Current loss value: 2245246700.0\n",
      "Image saved as content/output/output_at_iteration_78.png\n",
      "Iteration 78 completed in 370s\n",
      "Start of iteration 79\n",
      "Current loss value: 2224611600.0\n",
      "Image saved as content/output/output_at_iteration_79.png\n",
      "Iteration 79 completed in 370s\n",
      "Start of iteration 80\n",
      "Current loss value: 2205674800.0\n",
      "Image saved as content/output/output_at_iteration_80.png\n",
      "Iteration 80 completed in 373s\n",
      "Start of iteration 81\n",
      "Current loss value: 2187656000.0\n",
      "Image saved as content/output/output_at_iteration_81.png\n",
      "Iteration 81 completed in 376s\n",
      "Start of iteration 82\n",
      "Current loss value: 2166966300.0\n",
      "Image saved as content/output/output_at_iteration_82.png\n",
      "Iteration 82 completed in 373s\n",
      "Start of iteration 83\n",
      "Current loss value: 2143448300.0\n",
      "Image saved as content/output/output_at_iteration_83.png\n",
      "Iteration 83 completed in 374s\n",
      "Start of iteration 84\n",
      "Current loss value: 2123285100.0\n",
      "Image saved as content/output/output_at_iteration_84.png\n",
      "Iteration 84 completed in 371s\n",
      "Start of iteration 85\n",
      "Current loss value: 2104473600.0\n",
      "Image saved as content/output/output_at_iteration_85.png\n",
      "Iteration 85 completed in 370s\n",
      "Start of iteration 86\n",
      "Current loss value: 2090044400.0\n",
      "Image saved as content/output/output_at_iteration_86.png\n",
      "Iteration 86 completed in 379s\n",
      "Start of iteration 87\n",
      "Current loss value: 2075861400.0\n",
      "Image saved as content/output/output_at_iteration_87.png\n",
      "Iteration 87 completed in 373s\n",
      "Start of iteration 88\n",
      "Current loss value: 2062538800.0\n",
      "Image saved as content/output/output_at_iteration_88.png\n",
      "Iteration 88 completed in 387s\n",
      "Start of iteration 89\n",
      "Current loss value: 2049898200.0\n",
      "Image saved as content/output/output_at_iteration_89.png\n",
      "Iteration 89 completed in 392s\n",
      "Start of iteration 90\n",
      "Current loss value: 2030647800.0\n",
      "Image saved as content/output/output_at_iteration_90.png\n",
      "Iteration 90 completed in 391s\n",
      "Start of iteration 91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss\n",
    "x = preprocess_image(base_image_path)\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
    "    save_img(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
    "\n",
    "#Respuesta:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
    "\n",
    "#Respuesta:\n",
    "# combinaciones de pesos de las losses\n",
    "# primera ejecucion:\n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 10\n",
    "# content_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinaciones de pesos de las losses\n",
    "# segunda ejecucion:\n",
    "# total_variation_weight = 0.2\n",
    "# style_weight = 100\n",
    "# content_weight = 1\n",
    "# alfa (content_weight)/ beta (style_weight)\n",
    "# cambio un poco la intensidad de los colores, con esta combinacion tiene colores mas oscuros y mate\n",
    "# tiene pocas diferencias con respecto a la anterior configuracion pero se nota un poco en los colores \n",
    "# tendiendo hacia la paleta de colores de la imagen de estilo de referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinaciones de pesos de las losses\n",
    "# tercera ejecucion:\n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 1\n",
    "# content_weight = 10\n",
    "\n",
    "#se visualiza que las lineas, formas y estructura del contenido se mantiene,  muy poco varia a diferencia de la anterior \n",
    "# ejecucion donde las luces, y formas circulares tomaban mas la estructura de la imagen de referencia del estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinaciones de pesos de las losses\n",
    "# cuarta ejecucion:\n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 1\n",
    "# content_weight = 10000\n",
    "# muy claro que muestra pocos cambios de estilo y la paleta de colores es identica a la fotografia original\n",
    "# conserva claramente la estructura del contenido y tambien los colores, algunas lineas tienen el estilo de\n",
    "# la fotografia de referencia del estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
    "\n",
    "#Respuesta:\n",
    "\n",
    "# quinta ejecucion\n",
    "# imagenes diferentes\n",
    "# pesos \n",
    "# total_variation_weight = 0.1\n",
    "# style_weight = 1\n",
    "# content_weight = 10000\n",
    "# no se vio ningun cambio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sexta ejecucion\n",
    "# total_variation_weight = 0.2\n",
    "# style_weight = 100\n",
    "# content_weight = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
